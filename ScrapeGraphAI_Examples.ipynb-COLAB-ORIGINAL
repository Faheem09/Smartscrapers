{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfV5efDKjucs",
        "outputId": "36047a4b-69d4-4119-dd68-9757b0b9a98c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scrapegraphai in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (4.12.3)\n",
            "Requirement already satisfied: faiss-cpu==1.8.0 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (1.8.0)\n",
            "Requirement already satisfied: free-proxy==1.1.1 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (1.1.1)\n",
            "Requirement already satisfied: google==3.0.0 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (3.0.0)\n",
            "Requirement already satisfied: graphviz==0.20.3 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (0.20.3)\n",
            "Requirement already satisfied: html2text==2024.2.26 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (2024.2.26)\n",
            "Requirement already satisfied: langchain-anthropic==0.1.11 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (0.1.11)\n",
            "Requirement already satisfied: langchain-aws==0.1.3 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (0.1.3)\n",
            "Requirement already satisfied: langchain-google-genai==1.0.3 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (1.0.3)\n",
            "Requirement already satisfied: langchain-groq==0.1.3 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (0.1.3)\n",
            "Requirement already satisfied: langchain-openai==0.1.6 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (0.1.6)\n",
            "Requirement already satisfied: langchain==0.1.15 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (0.1.15)\n",
            "Requirement already satisfied: minify-html==0.15.0 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (0.15.0)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (2.2.2)\n",
            "Requirement already satisfied: playwright==1.43.0 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (1.43.0)\n",
            "Requirement already satisfied: python-dotenv==1.0.1 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (1.0.1)\n",
            "Requirement already satisfied: semchunk==1.0.1 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (1.0.1)\n",
            "Requirement already satisfied: tiktoken==0.6.0 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (0.6.0)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (4.66.4)\n",
            "Requirement already satisfied: undetected-playwright==0.3.0 in /usr/local/lib/python3.10/dist-packages (from scrapegraphai) (0.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.12.3->scrapegraphai) (2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu==1.8.0->scrapegraphai) (1.25.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from free-proxy==1.1.1->scrapegraphai) (4.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from free-proxy==1.1.1->scrapegraphai) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.41 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (0.1.82)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (2.7.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.15->scrapegraphai) (8.4.2)\n",
            "Requirement already satisfied: anthropic<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic==0.1.11->scrapegraphai) (0.30.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic==0.1.11->scrapegraphai) (0.7.1)\n",
            "Requirement already satisfied: boto3<1.35.0,>=1.34.51 in /usr/local/lib/python3.10/dist-packages (from langchain-aws==0.1.3->scrapegraphai) (1.34.137)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai==1.0.3->scrapegraphai) (0.5.4)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq==0.1.3->scrapegraphai) (0.9.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.6->scrapegraphai) (1.35.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->scrapegraphai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->scrapegraphai) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->scrapegraphai) (2024.1)\n",
            "Requirement already satisfied: greenlet==3.0.3 in /usr/local/lib/python3.10/dist-packages (from playwright==1.43.0->scrapegraphai) (3.0.3)\n",
            "Requirement already satisfied: pyee==11.1.0 in /usr/local/lib/python3.10/dist-packages (from playwright==1.43.0->scrapegraphai) (11.1.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.6.0->scrapegraphai) (2024.5.15)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee==11.1.0->playwright==1.43.0->scrapegraphai) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.15->scrapegraphai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.15->scrapegraphai) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.15->scrapegraphai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.15->scrapegraphai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.15->scrapegraphai) (1.9.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (0.19.1)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.137 in /usr/local/lib/python3.10/dist-packages (from boto3<1.35.0,>=1.34.51->langchain-aws==0.1.3->scrapegraphai) (1.34.137)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<1.35.0,>=1.34.51->langchain-aws==0.1.3->scrapegraphai) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<1.35.0,>=1.34.51->langchain-aws==0.1.3->scrapegraphai) (0.10.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.15->scrapegraphai) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.15->scrapegraphai) (0.9.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (1.24.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.15->scrapegraphai) (3.0.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.41->langchain==0.1.15->scrapegraphai) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.15->scrapegraphai) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.15->scrapegraphai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.15->scrapegraphai) (2.18.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->scrapegraphai) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->free-proxy==1.1.1->scrapegraphai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->free-proxy==1.1.1->scrapegraphai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->free-proxy==1.1.1->scrapegraphai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->free-proxy==1.1.1->scrapegraphai) (2024.6.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (1.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (4.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (0.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (0.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.15->scrapegraphai) (1.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (1.63.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.23.0->langchain-anthropic==0.1.11->scrapegraphai) (2023.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai==1.0.3->scrapegraphai) (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "#!pip install scrapegraphai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nit8sPf2mB3P",
        "outputId": "00ebd33d-9696-4131-daf2-8b14163749c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\u001b[39m\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:587:43)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:685:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:674:43)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/cli/program.js:119:7)\n"
          ]
        }
      ],
      "source": [
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe8spUuakwAI",
        "outputId": "46b03fa5-f238-4bba-d7e9-e3b782770638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'projects': [{'title': 'Rotary Pendulum RL', 'description': 'Open Source project aimed at controlling a real life rotary pendulum using RL algorithms'}, {'title': 'DQN Implementation from scratch', 'description': 'Developed a Deep Q-Network algorithm to train a simple and double pendulum'}, {'title': 'Multi Agents HAED', 'description': 'University project which focuses on simulating a multi-agent system to perform environment mapping. Agents, equipped with sensors, explore and record their surroundings, considering uncertainties in their readings.'}, {'title': 'Wireless ESC for Modular Drones', 'description': 'Modular drone architecture proposal and proof of concept. The project received maximum grade.'}]}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "#from dotenv import load_dotenv\n",
        "from scrapegraphai.graphs import SmartScraperGraph\n",
        "from scrapegraphai.utils import prettify_exec_info\n",
        "import nest_asyncio # Import nest_asyncio\n",
        "#load_dotenv()\n",
        "\n",
        "# openai_key = os.getenv(\"OPENAI_APIKEY\")\n",
        "openai_key = \"<<<ENTER YOUR OPENAI_APIKEY HERE... >>>\"\n",
        "graph_config = {\n",
        "   \"llm\": {\n",
        "      \"api_key\": openai_key,\n",
        "      \"model\": \"gpt-3.5-turbo\",\n",
        "   },\n",
        "}\n",
        "\n",
        "# ************************************************\n",
        "# Create the SmartScraperGraph instance and run it\n",
        "# ************************************************\n",
        "\n",
        "smart_scraper_graph = SmartScraperGraph(\n",
        "   prompt=\"List me all the projects with their description.\",\n",
        "   # also accepts a string with the already downloaded HTML code\n",
        "   source=\"https://perinim.github.io/projects/\",\n",
        "   config=graph_config\n",
        ")\n",
        "\n",
        "nest_asyncio.apply() # Apply nest_asyncio to allow nested event loops\n",
        "result = smart_scraper_graph.run()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ktx9-bLrcM9",
        "outputId": "321aa1db-fc2e-463b-973b-94ac937081a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"projects\": [\n",
            "        {\n",
            "            \"title\": \"Rotary Pendulum RL\",\n",
            "            \"description\": \"Open Source project aimed at controlling a real life rotary pendulum using RL algorithms\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"DQN Implementation from scratch\",\n",
            "            \"description\": \"Developed a Deep Q-Network algorithm to train a simple and double pendulum\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"Multi Agents HAED\",\n",
            "            \"description\": \"University project which focuses on simulating a multi-agent system to perform environment mapping. Agents, equipped with sensors, explore and record their surroundings, considering uncertainties in their readings.\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"Wireless ESC for Modular Drones\",\n",
            "            \"description\": \"Modular drone architecture proposal and proof of concept. The project received maximum grade.\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json # Import the json module\n",
        "# Pretty print the JSON result\n",
        "print(json.dumps(result, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW566Vlvr1PU",
        "outputId": "402faf9f-06ef-4abc-9af1-7f469c0c580d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                             title  \\\n",
            "0               Rotary Pendulum RL   \n",
            "1  DQN Implementation from scratch   \n",
            "2                Multi Agents HAED   \n",
            "3  Wireless ESC for Modular Drones   \n",
            "\n",
            "                                         description  \n",
            "0  Open Source project aimed at controlling a rea...  \n",
            "1  Developed a Deep Q-Network algorithm to train ...  \n",
            "2  University project which focuses on simulating...  \n",
            "3  Modular drone architecture proposal and proof ...  \n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'result' is the dictionary containing the extracted data\n",
        "df = pd.DataFrame(result['projects'])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dl37GYx3tbkL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4z46FEEtgN_",
        "outputId": "6be610a2-6844-4c7e-ae0c-f4e787b466d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'projects': [{'title': 'Rotary Pendulum RL', 'description': 'Open Source project aimed at controlling a real life rotary pendulum using RL algorithms'}, {'title': 'DQN Implementation from scratch', 'description': 'Developed a Deep Q-Network algorithm to train a simple and double pendulum'}, {'title': 'Multi Agents HAED', 'description': 'University project which focuses on simulating a multi-agent system to perform environment mapping. Agents, equipped with sensors, explore and record their surroundings, considering uncertainties in their readings.'}, {'title': 'Wireless ESC for Modular Drones', 'description': 'Modular drone architecture proposal and proof of concept. The project received maximum grade.'}]}\n",
            "{\n",
            "    \"projects\": [\n",
            "        {\n",
            "            \"title\": \"Rotary Pendulum RL\",\n",
            "            \"description\": \"Open Source project aimed at controlling a real life rotary pendulum using RL algorithms\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"DQN Implementation from scratch\",\n",
            "            \"description\": \"Developed a Deep Q-Network algorithm to train a simple and double pendulum\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"Multi Agents HAED\",\n",
            "            \"description\": \"University project which focuses on simulating a multi-agent system to perform environment mapping. Agents, equipped with sensors, explore and record their surroundings, considering uncertainties in their readings.\"\n",
            "        },\n",
            "        {\n",
            "            \"title\": \"Wireless ESC for Modular Drones\",\n",
            "            \"description\": \"Modular drone architecture proposal and proof of concept. The project received maximum grade.\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "                             title  \\\n",
            "0               Rotary Pendulum RL   \n",
            "1  DQN Implementation from scratch   \n",
            "2                Multi Agents HAED   \n",
            "3  Wireless ESC for Modular Drones   \n",
            "\n",
            "                                         description  \n",
            "0  Open Source project aimed at controlling a rea...  \n",
            "1  Developed a Deep Q-Network algorithm to train ...  \n",
            "2  University project which focuses on simulating...  \n",
            "3  Modular drone architecture proposal and proof ...  \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json # Import the json module\n",
        "import pandas as pd\n",
        "from scrapegraphai.graphs import SmartScraperGraph\n",
        "from scrapegraphai.utils import prettify_exec_info\n",
        "import nest_asyncio # Import nest_asyncio\n",
        "\n",
        "# openai_key = os.getenv(\"OPENAI_APIKEY\")\n",
        "openai_key = \"<<< ENTER YOUR OPENAI_APIKEY HERE >>>\"\n",
        "graph_config = {\n",
        "   \"llm\": {\n",
        "      \"api_key\": openai_key,\n",
        "      \"model\": \"gpt-3.5-turbo\",\n",
        "   },\n",
        "}\n",
        "\n",
        "# ************************************************\n",
        "# Create the SmartScraperGraph instance and run it\n",
        "# ************************************************\n",
        "\n",
        "smart_scraper_graph = SmartScraperGraph(\n",
        "   prompt=\"List me all the projects with their description.\",\n",
        "   # also accepts a string with the already downloaded HTML code\n",
        "   source=\"https://perinim.github.io/projects/\",\n",
        "   config=graph_config\n",
        ")\n",
        "\n",
        "nest_asyncio.apply() # Apply nest_asyncio to allow nested event loops\n",
        "result = smart_scraper_graph.run()\n",
        "print(result)\n",
        "\n",
        "# Pretty print the JSON result\n",
        "print(json.dumps(result, indent=4))\n",
        "\n",
        "# Assuming 'result' is the dictionary containing the extracted data\n",
        "df = pd.DataFrame(result['projects'])\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PSVomCOvktB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb28g8HtvBae",
        "outputId": "59a74ccc-3aeb-42aa-a014-1a9d07ea7732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                             title                                                                                                                                                                                                             description\n",
            "0               Rotary Pendulum RL                                                                                                                                Open Source project aimed at controlling a real life rotary pendulum using RL algorithms\n",
            "1  DQN Implementation from scratch                                                                                                                                              Developed a Deep Q-Network algorithm to train a simple and double pendulum\n",
            "2                Multi Agents HAED  University project which focuses on simulating a multi-agent system to perform environment mapping. Agents, equipped with sensors, explore and record their surroundings, considering uncertainties in their readings.\n",
            "3  Wireless ESC for Modular Drones                                                                                                                           Modular drone architecture proposal and proof of concept. The project received maximum grade.\n"
          ]
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)  # Show full content of columns\n",
        "pd.set_option('display.width', 1000)         # Widen the display area\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qgr4ZjlvmEF"
      },
      "outputs": [],
      "source": [
        "smart_scraper_graph = SmartScraperGraph(\n",
        "   prompt=\"List me all the projects with their description.\",\n",
        "   # also accepts a string with the already downloaded HTML code\n",
        "   source=\"https://perinim.github.io/projects/\",\n",
        "   config=graph_config\n",
        ")\n",
        "\n",
        "nest_asyncio.apply() # Apply nest_asyncio to allow nested event loops\n",
        "result = smart_scraper_graph.run()\n",
        "print(result)\n",
        "\n",
        "# Pretty print the JSON result\n",
        "print(json.dumps(result, indent=4))\n",
        "\n",
        "# Assuming 'result' is the dictionary containing the extracted data\n",
        "df = pd.DataFrame(result['projects'])\n",
        "\n",
        "print(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
